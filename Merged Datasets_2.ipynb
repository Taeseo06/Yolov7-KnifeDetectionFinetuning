{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPL77eybw4DdsaSMygWtHvo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iuwYg1ORw9BG"},"outputs":[],"source":["# coco Îç∞Ïù¥ÌÑ∞ÏÖãÏùÑ Ïó¨Îü¨Î≤à ÌïôÏäµÏãúÌÇ§Í≥† Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã ÌïôÏäµ (a100 ÏÇ¨Ïö©)"]},{"cell_type":"markdown","source":["# YOLOv7 ÌÅ¥Î°†, ÏÑ§Ï†ï & Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥"],"metadata":{"id":"kAWOxunxuf9x"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pP1iOD_exRzF","executionInfo":{"status":"ok","timestamp":1702790472805,"user_tz":-540,"elapsed":27931,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"fdcef463-d3b3-46ac-b3fa-729fdc60c043"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0rDX8DMuVpQ","executionInfo":{"status":"ok","timestamp":1702790524898,"user_tz":-540,"elapsed":5081,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"903251b8-7398-43ff-aea9-8e2cb222196a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.10.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.105.0)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n","Requirement already satisfied: gradio-client==0.7.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.3)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.2)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (2023.6.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (11.0.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.5)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"]}]},{"cell_type":"markdown","source":["## YOLOv7 Îã§Ïö¥ Î∞è ÏÑ§Ï†ï"],"metadata":{"id":"vxH0txqGup5P"}},{"cell_type":"code","source":["!git clone https://github.com/WongKinYiu/yolov7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjQIY9_OxXRf","executionInfo":{"status":"ok","timestamp":1702790519201,"user_tz":-540,"elapsed":5675,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"0e242f9a-fc2f-49a4-93e6-6227b7c19651"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n","Receiving objects: 100% (1197/1197), 74.24 MiB | 24.40 MiB/s, done.\n","Resolving deltas: 100% (518/518), done.\n"]}]},{"cell_type":"code","source":["%cd /content\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt # yolov7x Î™®Îç∏ Îã§Ïö¥\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt # yolov7 Î™®Îç∏ Îã§Ïö¥"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZUXQb9nxZBi","executionInfo":{"status":"ok","timestamp":1702790533287,"user_tz":-540,"elapsed":4384,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"978f4d83-ee0f-4af5-b438-f0807b1d6e41"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","--2023-12-17 05:22:08--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/c0e9f375-a42b-45d5-9e96-3156476cf121?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052208Z&X-Amz-Expires=300&X-Amz-Signature=eea9a7a997b07acd96c1a9dac356ab2919cad53950c6872aa72803f10e61218a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7x.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-12-17 05:22:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/c0e9f375-a42b-45d5-9e96-3156476cf121?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052208Z&X-Amz-Expires=300&X-Amz-Signature=eea9a7a997b07acd96c1a9dac356ab2919cad53950c6872aa72803f10e61218a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7x.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 143099649 (136M) [application/octet-stream]\n","Saving to: ‚Äòyolov7x.pt‚Äô\n","\n","yolov7x.pt          100%[===================>] 136.47M  72.8MB/s    in 1.9s    \n","\n","2023-12-17 05:22:10 (72.8 MB/s) - ‚Äòyolov7x.pt‚Äô saved [143099649/143099649]\n","\n","--2023-12-17 05:22:10--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052211Z&X-Amz-Expires=300&X-Amz-Signature=37155e480dbb7a8002d51728536f6276ad1149fdb18a4f16c19ad26956af57c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-12-17 05:22:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052211Z&X-Amz-Expires=300&X-Amz-Signature=37155e480dbb7a8002d51728536f6276ad1149fdb18a4f16c19ad26956af57c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75587165 (72M) [application/octet-stream]\n","Saving to: ‚Äòyolov7.pt‚Äô\n","\n","yolov7.pt           100%[===================>]  72.08M  71.6MB/s    in 1.0s    \n","\n","2023-12-17 05:22:12 (71.6 MB/s) - ‚Äòyolov7.pt‚Äô saved [75587165/75587165]\n","\n"]}]},{"cell_type":"code","source":["%cd yolov7\n","!pip install -r requirements.txt # YOLO Ï¢ÖÏÜçÏÑ± ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÑ§Ïπò"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YpE89zVxbnV","executionInfo":{"status":"ok","timestamp":1702790545589,"user_tz":-540,"elapsed":7207,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"b6b9d6c1-8ddd-4ec4-e7cc-2df7f6158907"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu121)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Collecting thop (from -r requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.60.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"markdown","source":["## Îç∞Ïù¥ÌÑ∞ÏÖã Îã§Ïö¥ & Îç∞Ïù¥ÌÑ∞ÏÖã 2Í∞ú Î≥ëÌï©"],"metadata":{"id":"Dh3DpKx8uvG4"}},{"cell_type":"code","source":["%cd /content\n","!pip install roboflow\n","from roboflow import Roboflow\n","\n","# 1Î≤àÏß∏ knife Îç∞Ïù¥ÌÑ∞ÏÖã - https://universe.roboflow.com/nuscrimesocietydatasets/knives-v2/dataset/2\n","rf = Roboflow(api_key=\"FhfkvOwLXnAMUM10Fsw9\") # roboflow api key ÏÑ§Ï†ï\n","project = rf.workspace(\"nuscrimesocietydatasets\").project(\"knives-v2\")\n","dataset = project.version(2).download(\"yolov7\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3RxuuXxoxf6n","executionInfo":{"status":"ok","timestamp":1702790573497,"user_tz":-540,"elapsed":23861,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"ac500c9a-9b81-48f0-cb4f-59c13ebd842f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Collecting roboflow\n","  Downloading roboflow-1.1.12-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Collecting pyparsing==2.4.7 (from roboflow)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.46.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.8.1.78\n","    Uninstalling opencv-python-headless-4.8.1.78:\n","      Successfully uninstalled opencv-python-headless-4.8.1.78\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2023.11.17\n","    Uninstalling certifi-2023.11.17:\n","      Successfully uninstalled certifi-2023.11.17\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.12 supervision-0.17.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","pyparsing"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Knives-V2-2 to yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78850/78850 [00:05<00:00, 14395.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Knives-V2-2 in yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7106/7106 [00:00<00:00, 9635.12it/s] \n"]}]},{"cell_type":"code","source":["!mv /content/Knives-V2-2 /content/dataset # Ï≤´ Î≤àÏß∏ Îç∞Ïù¥ÌÑ∞ÏÖã Ìè¥Îçî Ïù¥Î¶ÑÎ≥ÄÍ≤Ω"],"metadata":{"id":"NlccNl7kxf9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content\n","# 2Î≤àÏß∏ knife Îç∞Ïù¥ÌÑ∞ÏÖã - https://universe.roboflow.com/bmstu-uq0nx/knife-detection-yolov7/dataset/11#\n","rf = Roboflow(api_key=\"FhfkvOwLXnAMUM10Fsw9\") # roboflow api key ÏÑ§Ï†ï\n","project = rf.workspace(\"bmstu-uq0nx\").project(\"knife-detection-yolov7\")\n","dataset = project.version(11).download(\"yolov7\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSlmi7RJxnyc","executionInfo":{"status":"ok","timestamp":1700737420512,"user_tz":-540,"elapsed":13091,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"782163bc-bef8-4d2a-d588-3a10f0c7a578"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in knife-detection-yolov7-11 to yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 156187/156187 [00:08<00:00, 18725.13it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to knife-detection-yolov7-11 in yolov7pytorch:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6862/6862 [00:00<00:00, 7866.29it/s]\n"]}]},{"cell_type":"code","source":["!mv /content/knife-detection-yolov7-11 /content/dataset_m # Îëê Î≤àÏß∏ Îç∞Ïù¥ÌÑ∞ÏÖã ÎîîÎ†â Ïù¥Î¶ÑÎ≥ÄÍ≤Ω - (ÏûÑÏãú Îç∞Ïù¥ÌÑ∞ÏÖã Ìè¥Îçî)"],"metadata":{"id":"AlqN9iSqxpWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/train/images\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/train/images\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/train/labels\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/train/labels\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)"],"metadata":{"id":"kq07cQ3zxrGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/test/images\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/test/images\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/test/labels\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/test/labels\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)"],"metadata":{"id":"qlX-vwT5xxdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/valid/images\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/valid/images\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels Ïù¥Îèô\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","src_dir_path = \"/content/dataset_m/valid/labels\"\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","dest_dir_path = \"/content/dataset/valid/labels\"\n","\n","# ÏÜåÏä§ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Ïùò Î™®Îì† ÌååÏùº Î™©Î°ùÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt ÌååÏùºÎßå Ï∂îÏ∂úÌï©ÎãàÎã§.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n"],"metadata":{"id":"wgo4coG_x0H7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():\n","    print(\"CUDA ÏÇ¨Ïö© Í∞ÄÎä•\")\n","else:\n","    print(\"CUDA ÏÇ¨Ïö© Î∂àÍ∞ÄÎä•\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipveWW9ax1fG","executionInfo":{"status":"ok","timestamp":1700737301645,"user_tz":-540,"elapsed":4107,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"d91e4b43-92e2-4b19-89e6-2ca425864a07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA ÏÇ¨Ïö© Í∞ÄÎä•\n"]}]},{"cell_type":"code","source":["%cd /content/yolov7\n","!python train.py --workers 1 --device 0 --batch-size 5 --epochs 0 --img 416 416 --data /content/yolov7/data/coco.yaml --hyp data/hyp.scratch.custom.yaml --cfg cfg/training/yolov7.yaml --name yolov7-custom --weights yolov7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVuQzzNi2tAC","executionInfo":{"status":"ok","timestamp":1700738803539,"user_tz":-540,"elapsed":1263071,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"28d76fee-55bb-4d45-b981-77b034bb1194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","2023-11-23 11:05:42.186204: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-23 11:05:42.234712: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-23 11:05:42.234761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-23 11:05:42.234787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-23 11:05:42.243477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-23 11:05:43.260764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR üöÄ v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40513.5625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/training/yolov7.yaml', data='/content/yolov7/data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=0, batch_size=5, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom', total_batch_size=5)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n","100% 72.1M/72.1M [00:00<00:00, 423MB/s]\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n","\n","Transferred 558/566 items from yolov7.pt\n","\n","WARNING: Dataset not found, nonexistent paths: ['/content/yolov7/coco/val2017.txt']\n","Downloading bash ./scripts/get_coco.sh ...\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip  ...\n","Downloading http://images.cocodataset.org/zips/train2017.zip ...\n","Downloading http://images.cocodataset.org/zips/val2017.zip ...\n","Downloading http://images.cocodataset.org/zips/test2017.zip ...\n","      %%   %TT oo% ttaal l Tot T o   t  a%%l   RR ee cc ee%ii vvReeeddc  e%%i  vXXeffdee rr%dd   X  fAevArevdre ar gaAegv eeS rpSaepgeeede  dS  p  eT eiTdmi em  e   T  i  mTal    %  RTeicmeeii meev     e    T  id %  Xf TeirTmdiem m e e  A C verage Sp uC eru err derT nei tnm \n","teT i\n","   m  Ce  u   r   r   e   n T t i \n"," m   e                         T       i   m   e           C u   r   r   e    n     t\n","             D  Dl  lo  oa  ad  d         U  UpD pll loo oaa ad  dd     T   o U tTp a oll to  aa  ld     S   p   eS Tnop tteD anl lto   a   dL   eS  fpLUteep nftl t oS  ap  deS  epL dee \n","t o\n","t 0 aS  lp 0 e   e     d0 S\n","0e   n   t00        0         L0  e 0 f    t 0      0S 0 p   e   e0  d \n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  168M  100  168M    0     0   137M      0  0:00:01  0:00:01 --:--:--  211M\n","100  777M  100  777M    0     0  10.3M      0  0:01:15  0:01:15 --:--:-- 10.6M\n","100 6339M  100 6339M    0     0  17.2M      0  0:06:08  0:06:08 --:--:-- 18.0M\n","100 18.0G  100 18.0G    0     0  16.5M      0  0:18:37  0:18:37 --:--:-- 16.9M\n","Dataset autodownload success\n","\n","Scaled weight_decay = 0.0005078125\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","Traceback (most recent call last):\n","  File \"/content/yolov7/train.py\", line 616, in <module>\n","    train(hyp, opt, device, tb_writer)\n","  File \"/content/yolov7/train.py\", line 196, in train\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 217, in __init__\n","    super().__init__(optimizer, last_epoch, verbose)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 78, in __init__\n","    self._initial_step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 84, in _initial_step\n","    self.step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 147, in step\n","    values = self.get_lr()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 264, in get_lr\n","    return [base_lr * lmbda(self.last_epoch)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 264, in <listcomp>\n","    return [base_lr * lmbda(self.last_epoch)\n","  File \"/content/yolov7/utils/general.py\", line 188, in <lambda>\n","    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\n","ZeroDivisionError: float division by zero\n"]}]},{"cell_type":"markdown","source":["# Îç∞Ïù¥ÌÑ∞ÏÖã Î≥ëÌï© Ï†ÑÏ≤òÎ¶¨"],"metadata":{"id":"gG_ULL2p_jU8"}},{"cell_type":"code","source":["# !cp /content/drive/MyDrive/Yolo_Project_v3/model_coco.pt /content/yolov7/coco_dataseet # coco Îç∞Ïù¥ÌÑ∞ÏÖã ÏïïÏ∂ú ÌååÏùºÏùÑ ÎìúÎùºÏù¥Î∏åÏóê ÏóÖÎ°úÎìú Ïã§Ìå®Ìï¥ÏÑú ÌïÑÏöîÏóÜÏùå"],"metadata":{"id":"LFGSGOtT2Esm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# coco_dataset Ïóê ÏûàÎäî image/.jpg ÌååÏùºÍ≥º labels/.txt ÌååÏùºÏùÑ ÎπÑÍµê\n","  # knife -> 43 index\n","\n","\n","!pip install opencv-python\n","\n","from google.colab.patches import cv2_imshow\n","\n","# Ïù¥ÎØ∏ÏßÄ ÌååÏùº Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","image_path = \"/content/yolov7/coco/images/train2017/000000202499\" + '.jpg'\n","\n","# Ïù¥ÎØ∏ÏßÄÎ•º ÏùΩÏäµÎãàÎã§.\n","image = cv2.imread(image_path)\n","\n","# Ïù¥ÎØ∏ÏßÄÎ•º ÌëúÏãúÌï©ÎãàÎã§.\n","cv2_imshow(image)\n","\n","# ÌÇ§Î•º ÎàÑÎ•¥Î©¥ Ï¢ÖÎ£åÌï©ÎãàÎã§.\n","# cv2.waitKey(0)\n","\n","import os\n","\n","# ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","directory_path = \"/content/yolov7/coco/labels/train2017/000000202499\" + '.txt'\n","\n","# ÌååÏùº Ïù¥Î¶ÑÏùÑ ÏßÄÏ†ïÌï©ÎãàÎã§.\n","# file_name = \"my_file.txt\"\n","\n","# ÌååÏùº Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","# file_path = os.path.join(directory_path, file_name)\n","\n","# ÌååÏùºÏùÑ ÏóΩÎãàÎã§.\n","with open(directory_path, \"r\") as f:\n","    # ÌååÏùº ÎÇ¥Ïö©ÏùÑ ÏùΩÏäµÎãàÎã§.\n","    data = f.read()\n","\n","# ÌååÏùº ÎÇ¥Ïö©ÏùÑ Ï∂úÎ†•Ìï©ÎãàÎã§.\n","print(data)\n","\n","'''\n","knife = 43 index ÌôïÏù∏\n","'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"TUNUs1ZRC1K6","executionInfo":{"status":"error","timestamp":1700737301645,"user_tz":-540,"elapsed":24,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"54beeba2-8b11-407c-a4af-ab907eee0ff7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5f0d4c1c5da6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Ïù¥ÎØ∏ÏßÄÎ•º ÏùΩÏäµÎãàÎã§.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Ïù¥ÎØ∏ÏßÄÎ•º ÌëúÏãúÌï©ÎãàÎã§.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}]},{"cell_type":"markdown","source":["### Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã labels Í∞ùÏ≤¥ ÌÅ¥ÎûòÏä§ Î≥ÄÍ≤Ω (0->43)"],"metadata":{"id":"tnBpT7t_ECjn"}},{"cell_type":"code","source":["# Í∏∞Ï°¥ dataset Ïùò ÎùºÎ≤®Îì§ Ï§ë Í∞ùÏ≤¥ ÌÅ¥ÎûòÏä§Í∞Ä 0Ïù∏ Í≤ÉÎì§ÏùÑ 43(knife)Î°ú Î≥ÄÍ≤Ω\n","\n","import os\n","\n","path_li = ['/content/dataset/train/labels', '/content/dataset/test/labels', '/content/dataset/valid/labels']\n","for path in path_li:\n","  class_to_replace = 0  # Î≥ÄÍ≤ΩÌïòÍ≥†Ïûê ÌïòÎäî ÌÅ¥ÎûòÏä§ Í∞í\n","  replacement_class = 43  # ÎåÄÏ≤¥Ìï† ÌÅ¥ÎûòÏä§ Í∞í\n","\n","  for filename in os.listdir(path):\n","      if filename.endswith('.txt'):\n","          filepath = os.path.join(path, filename)\n","          with open(filepath, 'r') as file:\n","              lines = file.readlines()\n","\n","          modified_lines = []\n","          for line in lines:\n","              line_split = line.strip().split()\n","              if line_split:  # ÎπÑÏñ¥ÏûàÎäî Ï§ÑÏùÄ Í±¥ÎÑàÎúÅÎãàÎã§\n","                  current_class = int(line_split[0])  # ÌòÑÏû¨ ÌÅ¥ÎûòÏä§ Í∞íÏùÑ Í∞ÄÏ†∏ÏòµÎãàÎã§\n","                  if current_class == class_to_replace:\n","                      line_split[0] = str(replacement_class)  # ÌÅ¥ÎûòÏä§Î•º Î≥ÄÍ≤ΩÌï©ÎãàÎã§\n","                  modified_line = ' '.join(line_split) + '\\n'\n","                  modified_lines.append(modified_line)\n","\n","          # Î≥ÄÍ≤ΩÎêú ÎÇ¥Ïö©ÏùÑ ÌååÏùºÏóê Îã§Ïãú ÏîÅÎãàÎã§\n","          with open(filepath, 'w') as file:\n","              file.writelines(modified_lines)"],"metadata":{"id":"YRZViGNR8cH8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ïù¥ÎØ∏ÏßÄÍ≤ΩÎ°ú -> **coco** txt ÌååÏùºÏóê Ï∂îÍ∞Ä\n","    -Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥ÎØ∏ÏßÄÎ•º coco Îç∞Ïù¥ÌÑ∞ÏÖã Ïù¥ÎØ∏ÏßÄ ÌååÏùºÎ°ú ÏòÆÍ∏∏Í≤ÉÏùÑ ÏÉùÍ∞ÅÌïòÍ≥† Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï®(ÏÉÅÎåÄÍ≤ΩÎ°ú)"],"metadata":{"id":"OHeFLvPRD9mb"}},{"cell_type":"code","source":["# ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","directory_path = \"/content/dataset/train/images\"\n","\n","# ÌååÏùº Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","file_path = '/content/yolov7/coco/train2017.txt'\n","\n","# ÌååÏùºÏùÑ ÏóΩÎãàÎã§.\n","with open(file_path, \"a\") as f:\n","    # ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ Î∞òÎ≥µÌï©ÎãàÎã§.\n","    for file in os.listdir(directory_path):\n","        # ÌååÏùº ÌôïÏû•ÏûêÍ∞Ä jpgÏù∏ÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.\n","        if file.endswith(\".jpg\"):\n","            # ÌååÏùº Ïù¥Î¶ÑÏùÑ Î∂ôÏó¨ÎÑ£ÏäµÎãàÎã§.\n","            f.write(\"./images/train2017/{}\\n\".format(file))"],"metadata":{"id":"EUij9pVk9573"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖãÏùò test ÎîîÎ†âÌÜ†Î¶¨Îäî coco Îç∞Ïù¥ÌÑ∞ÏÖãÏúºÎ°ú ÏòØÍ≤®ÏÑú ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå"],"metadata":{"id":"HIN18rDe_7UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","directory_path = \"/content/dataset/valid/images\"\n","\n","# ÌååÏùº Ïù¥Î¶ÑÏùÑ ÏßÄÏ†ïÌï©ÎãàÎã§.\n","# file_name = \"my_file.txt\"\n","\n","# ÌååÏùº Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","file_path = '/content/yolov7/coco/val2017.txt'\n","\n","# ÌååÏùºÏùÑ ÏóΩÎãàÎã§.\n","with open(file_path, \"a\") as f:\n","    # ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ Î∞òÎ≥µÌï©ÎãàÎã§.\n","    for file in os.listdir(directory_path):\n","        # ÌååÏùº ÌôïÏû•ÏûêÍ∞Ä jpgÏù∏ÏßÄ ÌôïÏù∏Ìï©ÎãàÎã§.\n","        if file.endswith(\".jpg\"):\n","            # ÌååÏùº Ïù¥Î¶ÑÏùÑ Î∂ôÏó¨ÎÑ£ÏäµÎãàÎã§.\n","            f.write(\"./images/val2017/{}\\n\".format(file))"],"metadata":{"id":"UWPc5GzQ_0tn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Îç∞Ïù¥ÌÑ∞ Ïù¥Îèô (Ïù¥ÎØ∏ÏßÄ ÌååÏùº >.jpg)"],"metadata":{"id":"cJ3kYnCpD6hz"}},{"cell_type":"code","source":["# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã train ÏïàÏóê ÏûàÎäî Ïù¥ÎØ∏ÏßÄ(jpg) -> coco Îç∞Ïù¥ÌÑ∞ÏÖã images train ÌååÏùºÎ°ú Ïù¥Îèô\n","\n","import shutil\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","source_directory_path = \"/content/dataset/train/images\"\n","\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","target_directory_path = \"/content/yolov7/coco/images/train2017\"\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ ÎåÄÏÉÅÏúºÎ°ú Î∞òÎ≥µÌï©ÎãàÎã§.\n","for file in os.listdir(source_directory_path):\n","    # ÌååÏùº Í≤ΩÎ°úÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"oTJzZZ1dAekC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã valid ÏïàÏóê ÏûàÎäî Ïù¥ÎØ∏ÏßÄ(jpg) -> coco Îç∞Ïù¥ÌÑ∞ÏÖã images val ÌååÏùºÎ°ú Ïù¥Îèô\n","\n","import shutil\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","source_directory_path = \"/content/dataset/valid/images\"\n","\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","target_directory_path = \"/content/yolov7/coco/images/val2017\"\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ ÎåÄÏÉÅÏúºÎ°ú Î∞òÎ≥µÌï©ÎãàÎã§.\n","for file in os.listdir(source_directory_path):\n","    # ÌååÏùº Í≤ΩÎ°úÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"8TBLruf5EKfl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Îç∞Ïù¥ÌÑ∞ Ïù¥Îèô (ÎùºÎ≤®ÌååÏùº >.txt)"],"metadata":{"id":"wwA89787EnWk"}},{"cell_type":"code","source":["# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã train ÏïàÏóê ÏûàÎäî Ïù¥ÎØ∏ÏßÄ(jpg) -> coco Îç∞Ïù¥ÌÑ∞ÏÖã images train ÌååÏùºÎ°ú Ïù¥Îèô\n","\n","import shutil\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","source_directory_path = \"/content/dataset/train/labels\"\n","\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","target_directory_path = \"/content/yolov7/coco/labels/train2017\"\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ ÎåÄÏÉÅÏúºÎ°ú Î∞òÎ≥µÌï©ÎãàÎã§.\n","for file in os.listdir(source_directory_path):\n","    # ÌååÏùº Í≤ΩÎ°úÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"Ytp6aotgFAQC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Í∏∞Ï°¥ Îç∞Ïù¥ÌÑ∞ÏÖã valid ÏïàÏóê ÏûàÎäî Ïù¥ÎØ∏ÏßÄ(jpg) -> coco Îç∞Ïù¥ÌÑ∞ÏÖã images val ÌååÏùºÎ°ú Ïù¥Îèô\n","\n","import shutil\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","source_directory_path = \"/content/dataset/valid/labels\"\n","\n","# ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨ Í≤ΩÎ°úÎ•º ÏßÄÏ†ïÌï©ÎãàÎã§.\n","target_directory_path = \"/content/yolov7/coco/labels/val2017\"\n","\n","# ÏõêÎ≥∏ ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥Î∂ÄÏùò Î™®Îì† ÌååÏùºÏùÑ ÎåÄÏÉÅÏúºÎ°ú Î∞òÎ≥µÌï©ÎãàÎã§.\n","for file in os.listdir(source_directory_path):\n","    # ÌååÏùº Í≤ΩÎ°úÎ•º Í∞ÄÏ†∏ÏòµÎãàÎã§.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # ÌååÏùºÏùÑ ÎåÄÏÉÅ ÎîîÎ†âÌÜ†Î¶¨Î°ú Ïù¥ÎèôÌï©ÎãàÎã§.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"wa2QvaE6EhQN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### coco.yaml ÌååÏùº Î≥ÄÍ≤Ω\n","\n","\n","```\n","train: ./coco/train2017.txt  # 118287 images + Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã\n","val: ./coco/val2017.txt  # 5000 images + Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã\n","test: ./coco/test-dev2017.txt  # 20288 of 40670 images, submit to https://competitions.codalab.org/competitions/20794\n","\n","# number of classes\n","nc: 80\n","\n","# class names\n","names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n","         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n","         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n","         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n","         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n","         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n","         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n","         'hair drier', 'toothbrush' ]\n","\n","```\n","\n"],"metadata":{"id":"zFUset5HF-5p"}},{"cell_type":"code","source":["# Í∏∞Ï°¥ coco.yaml ÌååÏùº ÏàòÏ†ï Î∂àÍ∞ÄÎ°ú Ïù∏Ìï¥ Í∏∞Ï°¥Îç∞Ïù¥ÌÑ∞ÏÖã data.yaml ÌååÏùº yolov7/data ÎîîÎ†âÏóê Î≥µÏÇ¨Ìï¥ÏôÄÏÑú ÏàòÏ†ïÌïÑÏöî\n","!cp /content/dataset/data.yaml /content/yolov7/data/data.yaml\n","\n","# ÏúÑ ÌÖçÏä§Ìä∏ÏÖ∏Ïùò ÏΩîÎìú ÎçÆÏñ¥Ïì∞Í∏∞ Î∞è Ï†ÄÏû• ÌïÑÏöî"],"metadata":{"id":"iONNXxuJHeZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Î™®Îç∏ ÌïôÏäµ"],"metadata":{"id":"2CpLJgPbIrfN"}},{"cell_type":"code","source":["%cd /content/yolov7\n","!python train.py --workers 1 --device 0 --batch-size 10 --epochs 8  --img 416 416 --data /content/yolov7/data/data.yaml --hyp data/hyp.scratch.custom.yaml --cfg cfg/training/yolov7.yaml --name yolov7-custom --weights yolov7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9NdbveNx3om","executionInfo":{"status":"ok","timestamp":1700785443749,"user_tz":-540,"elapsed":1340727,"user":{"displayName":"Î¨∏ÌÉúÏÑú","userId":"03540612891035297255"}},"outputId":"1f57b027-da50-4b2a-fce0-726b8e46182d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","2023-11-23 12:34:25.189238: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-23 12:34:25.238590: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-23 12:34:25.238654: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-23 12:34:25.238680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-23 12:34:25.247594: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-23 12:34:26.270387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR üöÄ v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40513.5625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/training/yolov7.yaml', data='/content/yolov7/data/data.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=8, batch_size=10, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom2', total_batch_size=10)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n","\n","Transferred 558/566 items from yolov7.pt\n","Scaled weight_decay = 0.00046875\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017' images and labels... 123152 found, 1021 missing, 0 empty, 0 corrupted: 100% 124173/124173 [01:43<00:00, 1204.85it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: coco/train2017.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017' images and labels... 5670 found, 48 missing, 0 empty, 0 corrupted: 100% 5718/5718 [00:12<00:00, 463.63it/s] \n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: coco/val2017.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.21, Best Possible Recall (BPR) = 0.9730. Attempting to improve anchors, please wait...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 15342 of 856018 labels are < 3 pixels in size.\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 855585 points...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9729 best possible recall, 4.00 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.272/0.653-mean/best, past_thr=0.468-mean: 14,14,  24,41,  62,36,  49,90,  126,78,  93,168,  246,134,  167,277,  356,262\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6891: 100% 1000/1000 [01:24<00:00, 11.78it/s]\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9952 best possible recall, 4.30 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.288/0.690-mean/best, past_thr=0.468-mean: 7,8,  9,21,  22,17,  22,42,  53,37,  46,89,  111,83,  105,184,  270,215\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n","\n","Image sizes 416 train, 416 test\n","Using 1 dataloader workers\n","Logging results to runs/train/yolov7-custom2\n","Starting training for 8 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/7     1.31G   0.02766   0.01852  0.009331   0.05551        52       416: 100% 12418/12418 [1:27:08<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [01:04<00:00,  4.44it/s]\n","                 all        5718       37083       0.428       0.496       0.417       0.259\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/7     3.96G   0.02925   0.02008   0.01139   0.06072        27       416: 100% 12418/12418 [1:26:44<00:00,  2.39it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.09it/s]\n","                 all        5718       37083        0.67       0.553       0.585       0.396\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/7     6.28G   0.03093   0.02151   0.01402   0.06647        46       416: 100% 12418/12418 [1:26:46<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.11it/s]\n","                 all        5718       37083       0.712       0.526       0.591       0.407\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/7     6.29G   0.03076   0.02165   0.01421   0.06662        21       416: 100% 12418/12418 [1:26:45<00:00,  2.39it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.11it/s]\n","                 all        5718       37083       0.666       0.552       0.591       0.407\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/7     6.29G   0.03007   0.02134   0.01347   0.06488        38       416: 100% 12418/12418 [1:26:50<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.12it/s]\n","                 all        5718       37083       0.671       0.556       0.596       0.411\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/7     6.29G   0.02905   0.02098   0.01241   0.06243        15       416: 100% 12418/12418 [1:27:02<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.12it/s]\n","                 all        5718       37083       0.697       0.548       0.601       0.417\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/7     6.29G     0.028   0.02047   0.01138   0.05985        35       416: 100% 12418/12418 [1:27:10<00:00,  2.37it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.10it/s]\n","                 all        5718       37083       0.698       0.554       0.606       0.421\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/7     6.29G   0.02712   0.01984    0.0105   0.05745        41       416: 100% 12418/12418 [1:26:53<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.07it/s]\n","                 all        5718       37083       0.687       0.564       0.611       0.425\n","8 epochs completed in 11.725 hours.\n","\n","Optimizer stripped from runs/train/yolov7-custom2/weights/last.pt, 75.6MB\n","Optimizer stripped from runs/train/yolov7-custom2/weights/best.pt, 75.6MB\n"]}]},{"cell_type":"code","source":["!cp -a /content/yolov7/runs/train/yolov7-custom2/weights/best.pt /content/drive/MyDrive/Yolo_Project_v3/modle.pt"],"metadata":{"id":"7NEgQBFCNfST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -a /content/yolov7/runs/train/yolov7-custom2/weights/best.pt /content/drive/MyDrive/Yolo_Project_v3/custom+coco.pt"],"metadata":{"id":"7kXl1SR9Pry2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Î™®Îç∏ Detect"],"metadata":{"id":"YbbEoEpWuE-9"}},{"cell_type":"code","source":["%cd /content/yolov7\n","!python /content/yolov7/detect.py --weights /content/yolov7/runs/train/yolov7-custom2/weights/best.pt --img 416 --conf 0.4 --source /content/detect_images/"],"metadata":{"id":"YJH5ZxMNuJcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import time\n","from pathlib import Path\n","\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n","    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n","\n","\n","def detect(source, conf_thres, save_img=True):\n","    # weights = '/content/model.pt'\n","    # weights = '/content/yolov7x.pt'\n","\n","    weights = '/content/drive/MyDrive/Yolo_Project_v3/custom+coco.pt' # coco + Ïª§Ïä§ÌÖÄ Îç∞Ïù¥ÌÑ∞ÏÖã2Í∞ú Î≥ëÌï©\n","\n","    source.save('/content/input.png')\n","    source = '/content/input.png'\n","    img_size = 640\n","    conf_thres = conf_thres\n","    iou_thres = 0.45\n","    device = ''\n","    view_img = False\n","    save_txt = False\n","    save_conf = False\n","    nosave = False\n","    classes = None\n","    agnostic_nms = False\n","    augment=False\n","    update = False\n","    project = 'runs/detect'\n","    name='exp'\n","    exist_ok=False\n","    no_trace=False\n","\n","    imgsz = img_size\n","    trace = no_trace\n","    #source, weights, view_img, save_txt, imgsz, trace = source, weights, view_img, save_txt, img_size, not no_trace\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n","        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n","\n","    # Directories\n","    save_dir = Path(increment_path(Path(project) / name, exist_ok=exist_ok))  # increment run\n","    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Initialize\n","    set_logging()\n","    device = select_device(device)\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","    stride = int(model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","\n","    if trace:\n","        model = TracedModel(model, device, img_size)\n","\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Second-stage classifier\n","    classify = False\n","    if classify:\n","        modelc = load_classifier(name='resnet101', n=2)  # initialize\n","        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    if webcam:\n","        view_img = check_imshow()\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n","\n","    # Run inference\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    old_img_w = old_img_h = imgsz\n","    old_img_b = 1\n","\n","    t0 = time.time()\n","    for path, img, im0s, vid_cap in dataset:\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Warmup\n","        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n","            old_img_b = img.shape[0]\n","            old_img_h = img.shape[2]\n","            old_img_w = img.shape[3]\n","            for i in range(3):\n","                model(img, augment=augment)[0]\n","\n","        # Inference\n","        t1 = time_synchronized()\n","        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","            pred = model(img, augment=augment)[0]\n","        t2 = time_synchronized()\n","\n","        # Apply NMS\n","        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n","        t3 = time_synchronized()\n","\n","        # Apply Classifier\n","        if classify:\n","            pred = apply_classifier(pred, modelc, img, im0s)\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            if webcam:  # batch_size >= 1\n","                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n","            else:\n","                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","\n","            p = Path(p)  # to Path\n","            save_path = str(save_dir / p.name)  # img.jpg\n","            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n","            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","            if len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results\n","                for c in det[:, -1].unique():\n","                    n = (det[:, -1] == c).sum()  # detections per class\n","                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","\n","                # Write results\n","                for *xyxy, conf, cls in reversed(det):\n","                    if save_txt:  # Write to file\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n","                        with open(txt_path + '.txt', 'a') as f:\n","                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n","\n","                    if save_img or view_img:  # Add bbox to image\n","                        label = f'{names[int(cls)]} {conf:.2f}'\n","                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n","\n","            # Print time (inference + NMS)\n","            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","\n","            # Stream results\n","            if view_img:\n","                cv2.imshow(str(p), im0)\n","                cv2.waitKey(1)  # 1 millisecond\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'image':\n","                    cv2.imwrite(save_path, im0)\n","                    print(f\" The image with the result is saved in: {save_path}\")\n","                else:  # 'video' or 'stream'\n","                    if vid_path != save_path:  # new video\n","                        vid_path = save_path\n","                        if isinstance(vid_writer, cv2.VideoWriter):\n","                            vid_writer.release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                            save_path += '.mp4'\n","                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer.write(im0)\n","\n","    if save_txt or save_img:\n","        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n","        #print(f\"Results saved to {save_dir}{s}\")\n","\n","    print(f'Done. ({time.time() - t0:.3f}s)')\n","    return Path(save_path)\n","\n","\n","# detect('/content/input.mp4', 0.3) # gradio ÏÇ¨Ïö©ÏóÜÏù¥ detect Ìï®ÏàòÏã§Ìñâ"],"metadata":{"id":"_gpNCr1FvcBj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gradio Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Ïó∞Í≤∞"],"metadata":{"id":"Er_eZ3uquSeu"}},{"cell_type":"code","source":["import gradio as gr\n","import os\n","\n","\n","demo = gr.Interface(\n","    fn=detect,\n","    inputs=[gr.Image(type='pil'),\n","    gr.Slider(\n","        0.0,\n","        1,\n","        step=0.01,\n","        value=0.3,\n","        label='conf',\n","        info='conf'\n","    )],\n","    outputs='image',\n",")\n","demo.launch(debug=True)"],"metadata":{"id":"zpgy51ABvbWH"},"execution_count":null,"outputs":[]}]}