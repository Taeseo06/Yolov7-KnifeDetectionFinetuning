{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPL77eybw4DdsaSMygWtHvo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iuwYg1ORw9BG"},"outputs":[],"source":["# coco 데이터셋을 여러번 학습시키고 커스텀 데이터셋 학습 (a100 사용)"]},{"cell_type":"markdown","source":["# YOLOv7 클론, 설정 & 데이터셋 다운"],"metadata":{"id":"kAWOxunxuf9x"}},{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pP1iOD_exRzF","executionInfo":{"status":"ok","timestamp":1702790472805,"user_tz":-540,"elapsed":27931,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"fdcef463-d3b3-46ac-b3fa-729fdc60c043"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k0rDX8DMuVpQ","executionInfo":{"status":"ok","timestamp":1702790524898,"user_tz":-540,"elapsed":5081,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"903251b8-7398-43ff-aea9-8e2cb222196a"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.10.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.105.0)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n","Requirement already satisfied: gradio-client==0.7.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.7.3)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.2)\n","Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.2)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.0.post1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (2023.6.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.3->gradio) (11.0.3)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.5)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n","Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n","Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.27.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.2.0)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.2)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"]}]},{"cell_type":"markdown","source":["## YOLOv7 다운 및 설정"],"metadata":{"id":"vxH0txqGup5P"}},{"cell_type":"code","source":["!git clone https://github.com/WongKinYiu/yolov7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjQIY9_OxXRf","executionInfo":{"status":"ok","timestamp":1702790519201,"user_tz":-540,"elapsed":5675,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"0e242f9a-fc2f-49a4-93e6-6227b7c19651"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n","Receiving objects: 100% (1197/1197), 74.24 MiB | 24.40 MiB/s, done.\n","Resolving deltas: 100% (518/518), done.\n"]}]},{"cell_type":"code","source":["%cd /content\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt # yolov7x 모델 다운\n","!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt # yolov7 모델 다운"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZUXQb9nxZBi","executionInfo":{"status":"ok","timestamp":1702790533287,"user_tz":-540,"elapsed":4384,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"978f4d83-ee0f-4af5-b438-f0807b1d6e41"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","--2023-12-17 05:22:08--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7x.pt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/c0e9f375-a42b-45d5-9e96-3156476cf121?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052208Z&X-Amz-Expires=300&X-Amz-Signature=eea9a7a997b07acd96c1a9dac356ab2919cad53950c6872aa72803f10e61218a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7x.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-12-17 05:22:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/c0e9f375-a42b-45d5-9e96-3156476cf121?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052208Z&X-Amz-Expires=300&X-Amz-Signature=eea9a7a997b07acd96c1a9dac356ab2919cad53950c6872aa72803f10e61218a&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7x.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 143099649 (136M) [application/octet-stream]\n","Saving to: ‘yolov7x.pt’\n","\n","yolov7x.pt          100%[===================>] 136.47M  72.8MB/s    in 1.9s    \n","\n","2023-12-17 05:22:10 (72.8 MB/s) - ‘yolov7x.pt’ saved [143099649/143099649]\n","\n","--2023-12-17 05:22:10--  https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt\n","Resolving github.com (github.com)... 20.27.177.113\n","Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052211Z&X-Amz-Expires=300&X-Amz-Signature=37155e480dbb7a8002d51728536f6276ad1149fdb18a4f16c19ad26956af57c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream [following]\n","--2023-12-17 05:22:11--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/511187726/b0243edf-9fb0-4337-95e1-42555f1b37cf?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20231217%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20231217T052211Z&X-Amz-Expires=300&X-Amz-Signature=37155e480dbb7a8002d51728536f6276ad1149fdb18a4f16c19ad26956af57c8&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=511187726&response-content-disposition=attachment%3B%20filename%3Dyolov7.pt&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 75587165 (72M) [application/octet-stream]\n","Saving to: ‘yolov7.pt’\n","\n","yolov7.pt           100%[===================>]  72.08M  71.6MB/s    in 1.0s    \n","\n","2023-12-17 05:22:12 (71.6 MB/s) - ‘yolov7.pt’ saved [75587165/75587165]\n","\n"]}]},{"cell_type":"code","source":["%cd yolov7\n","!pip install -r requirements.txt # YOLO 종속성 라이브러리 설치"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9YpE89zVxbnV","executionInfo":{"status":"ok","timestamp":1702790545589,"user_tz":-540,"elapsed":7207,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"b6b9d6c1-8ddd-4ec4-e7cc-2df7f6158907"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.4)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu121)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.15.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Collecting thop (from -r requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.60.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.43)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.9.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.12)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"markdown","source":["## 데이터셋 다운 & 데이터셋 2개 병합"],"metadata":{"id":"Dh3DpKx8uvG4"}},{"cell_type":"code","source":["%cd /content\n","!pip install roboflow\n","from roboflow import Roboflow\n","\n","# 1번째 knife 데이터셋 - https://universe.roboflow.com/nuscrimesocietydatasets/knives-v2/dataset/2\n","rf = Roboflow(api_key=\"FhfkvOwLXnAMUM10Fsw9\") # roboflow api key 설정\n","project = rf.workspace(\"nuscrimesocietydatasets\").project(\"knives-v2\")\n","dataset = project.version(2).download(\"yolov7\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3RxuuXxoxf6n","executionInfo":{"status":"ok","timestamp":1702790573497,"user_tz":-540,"elapsed":23861,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"ac500c9a-9b81-48f0-cb4f-59c13ebd842f"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Collecting roboflow\n","  Downloading roboflow-1.1.12-py3-none-any.whl (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting certifi==2023.7.22 (from roboflow)\n","  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n","  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n","  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n","Collecting idna==2.10 (from roboflow)\n","  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n","Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n","  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n","Collecting pyparsing==2.4.7 (from roboflow)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n","Collecting python-dotenv (from roboflow)\n","  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n","Collecting supervision (from roboflow)\n","  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n","Collecting requests-toolbelt (from roboflow)\n","  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting python-magic (from roboflow)\n","  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.2.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.46.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.2)\n","Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.4)\n","Installing collected packages: python-magic, python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: opencv-python-headless\n","    Found existing installation: opencv-python-headless 4.8.1.78\n","    Uninstalling opencv-python-headless-4.8.1.78:\n","      Successfully uninstalled opencv-python-headless-4.8.1.78\n","  Attempting uninstall: idna\n","    Found existing installation: idna 3.6\n","    Uninstalling idna-3.6:\n","      Successfully uninstalled idna-3.6\n","  Attempting uninstall: cycler\n","    Found existing installation: cycler 0.12.1\n","    Uninstalling cycler-0.12.1:\n","      Successfully uninstalled cycler-0.12.1\n","  Attempting uninstall: chardet\n","    Found existing installation: chardet 5.2.0\n","    Uninstalling chardet-5.2.0:\n","      Successfully uninstalled chardet-5.2.0\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2023.11.17\n","    Uninstalling certifi-2023.11.17:\n","      Successfully uninstalled certifi-2023.11.17\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.12 supervision-0.17.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["certifi","cycler","pyparsing"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Knives-V2-2 to yolov7pytorch:: 100%|██████████| 78850/78850 [00:05<00:00, 14395.94it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Knives-V2-2 in yolov7pytorch:: 100%|██████████| 7106/7106 [00:00<00:00, 9635.12it/s] \n"]}]},{"cell_type":"code","source":["!mv /content/Knives-V2-2 /content/dataset # 첫 번째 데이터셋 폴더 이름변경"],"metadata":{"id":"NlccNl7kxf9O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content\n","# 2번째 knife 데이터셋 - https://universe.roboflow.com/bmstu-uq0nx/knife-detection-yolov7/dataset/11#\n","rf = Roboflow(api_key=\"FhfkvOwLXnAMUM10Fsw9\") # roboflow api key 설정\n","project = rf.workspace(\"bmstu-uq0nx\").project(\"knife-detection-yolov7\")\n","dataset = project.version(11).download(\"yolov7\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KSlmi7RJxnyc","executionInfo":{"status":"ok","timestamp":1700737420512,"user_tz":-540,"elapsed":13091,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"782163bc-bef8-4d2a-d588-3a10f0c7a578"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in knife-detection-yolov7-11 to yolov7pytorch:: 100%|██████████| 156187/156187 [00:08<00:00, 18725.13it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to knife-detection-yolov7-11 in yolov7pytorch:: 100%|██████████| 6862/6862 [00:00<00:00, 7866.29it/s]\n"]}]},{"cell_type":"code","source":["!mv /content/knife-detection-yolov7-11 /content/dataset_m # 두 번째 데이터셋 디렉 이름변경 - (임시 데이터셋 폴더)"],"metadata":{"id":"AlqN9iSqxpWB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/train/images\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/train/images\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/train/labels\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/train/labels\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)"],"metadata":{"id":"kq07cQ3zxrGY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/test/images\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/test/images\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/test/labels\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/test/labels\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)"],"metadata":{"id":"qlX-vwT5xxdB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# images 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/valid/images\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/valid/images\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# jpg 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".jpg\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n","# labels 이동\n","\n","# 소스 디렉토리의 경로를 지정합니다.\n","src_dir_path = \"/content/dataset_m/valid/labels\"\n","# 대상 디렉토리의 경로를 지정합니다.\n","dest_dir_path = \"/content/dataset/valid/labels\"\n","\n","# 소스 디렉토리 내의 모든 파일 목록을 가져옵니다.\n","file_list = os.listdir(src_dir_path)\n","\n","# txt 파일만 추출합니다.\n","for file_name in file_list:\n","    if file_name.endswith(\".txt\"):\n","        # 파일을 대상 디렉토리로 이동합니다.\n","        new_path = os.path.join(dest_dir_path, file_name)\n","        os.rename(os.path.join(src_dir_path, file_name), new_path)\n","\n"],"metadata":{"id":"wgo4coG_x0H7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():\n","    print(\"CUDA 사용 가능\")\n","else:\n","    print(\"CUDA 사용 불가능\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ipveWW9ax1fG","executionInfo":{"status":"ok","timestamp":1700737301645,"user_tz":-540,"elapsed":4107,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"d91e4b43-92e2-4b19-89e6-2ca425864a07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CUDA 사용 가능\n"]}]},{"cell_type":"code","source":["%cd /content/yolov7\n","!python train.py --workers 1 --device 0 --batch-size 5 --epochs 0 --img 416 416 --data /content/yolov7/data/coco.yaml --hyp data/hyp.scratch.custom.yaml --cfg cfg/training/yolov7.yaml --name yolov7-custom --weights yolov7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eVuQzzNi2tAC","executionInfo":{"status":"ok","timestamp":1700738803539,"user_tz":-540,"elapsed":1263071,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"28d76fee-55bb-4d45-b981-77b034bb1194"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","2023-11-23 11:05:42.186204: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-23 11:05:42.234712: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-23 11:05:42.234761: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-23 11:05:42.234787: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-23 11:05:42.243477: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-23 11:05:43.260764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40513.5625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/training/yolov7.yaml', data='/content/yolov7/data/coco.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=0, batch_size=5, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom', total_batch_size=5)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","Downloading https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt to yolov7.pt...\n","100% 72.1M/72.1M [00:00<00:00, 423MB/s]\n","\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n","\n","Transferred 558/566 items from yolov7.pt\n","\n","WARNING: Dataset not found, nonexistent paths: ['/content/yolov7/coco/val2017.txt']\n","Downloading bash ./scripts/get_coco.sh ...\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/coco2017labels-segments.zip  ...\n","Downloading http://images.cocodataset.org/zips/train2017.zip ...\n","Downloading http://images.cocodataset.org/zips/val2017.zip ...\n","Downloading http://images.cocodataset.org/zips/test2017.zip ...\n","      %%   %TT oo% ttaal l Tot T o   t  a%%l   RR ee cc ee%ii vvReeeddc  e%%i  vXXeffdee rr%dd   X  fAevArevdre ar gaAegv eeS rpSaepgeeede  dS  p  eT eiTdmi em  e   T  i  mTal    %  RTeicmeeii meev     e    T  id %  Xf TeirTmdiem m e e  A C verage Sp uC eru err derT nei tnm \n","teT i\n","   m  Ce  u   r   r   e   n T t i \n"," m   e                         T       i   m   e           C u   r   r   e    n     t\n","             D  Dl  lo  oa  ad  d         U  UpD pll loo oaa ad  dd     T   o U tTp a oll to  aa  ld     S   p   eS Tnop tteD anl lto   a   dL   eS  fpLUteep nftl t oS  ap  deS  epL dee \n","t o\n","t 0 aS  lp 0 e   e     d0 S\n","0e   n   t00        0         L0  e 0 f    t 0      0S 0 p   e   e0  d \n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100  168M  100  168M    0     0   137M      0  0:00:01  0:00:01 --:--:--  211M\n","100  777M  100  777M    0     0  10.3M      0  0:01:15  0:01:15 --:--:-- 10.6M\n","100 6339M  100 6339M    0     0  17.2M      0  0:06:08  0:06:08 --:--:-- 18.0M\n","100 18.0G  100 18.0G    0     0  16.5M      0  0:18:37  0:18:37 --:--:-- 16.9M\n","Dataset autodownload success\n","\n","Scaled weight_decay = 0.0005078125\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","Traceback (most recent call last):\n","  File \"/content/yolov7/train.py\", line 616, in <module>\n","    train(hyp, opt, device, tb_writer)\n","  File \"/content/yolov7/train.py\", line 196, in train\n","    scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 217, in __init__\n","    super().__init__(optimizer, last_epoch, verbose)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 78, in __init__\n","    self._initial_step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 84, in _initial_step\n","    self.step()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 147, in step\n","    values = self.get_lr()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 264, in get_lr\n","    return [base_lr * lmbda(self.last_epoch)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py\", line 264, in <listcomp>\n","    return [base_lr * lmbda(self.last_epoch)\n","  File \"/content/yolov7/utils/general.py\", line 188, in <lambda>\n","    return lambda x: ((1 - math.cos(x * math.pi / steps)) / 2) * (y2 - y1) + y1\n","ZeroDivisionError: float division by zero\n"]}]},{"cell_type":"markdown","source":["# 데이터셋 병합 전처리"],"metadata":{"id":"gG_ULL2p_jU8"}},{"cell_type":"code","source":["# !cp /content/drive/MyDrive/Yolo_Project_v3/model_coco.pt /content/yolov7/coco_dataseet # coco 데이터셋 압출 파일을 드라이브에 업로드 실패해서 필요없음"],"metadata":{"id":"LFGSGOtT2Esm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# coco_dataset 에 있는 image/.jpg 파일과 labels/.txt 파일을 비교\n","  # knife -> 43 index\n","\n","\n","!pip install opencv-python\n","\n","from google.colab.patches import cv2_imshow\n","\n","# 이미지 파일 경로를 지정합니다.\n","image_path = \"/content/yolov7/coco/images/train2017/000000202499\" + '.jpg'\n","\n","# 이미지를 읽습니다.\n","image = cv2.imread(image_path)\n","\n","# 이미지를 표시합니다.\n","cv2_imshow(image)\n","\n","# 키를 누르면 종료합니다.\n","# cv2.waitKey(0)\n","\n","import os\n","\n","# 디렉토리 경로를 지정합니다.\n","directory_path = \"/content/yolov7/coco/labels/train2017/000000202499\" + '.txt'\n","\n","# 파일 이름을 지정합니다.\n","# file_name = \"my_file.txt\"\n","\n","# 파일 경로를 지정합니다.\n","# file_path = os.path.join(directory_path, file_name)\n","\n","# 파일을 엽니다.\n","with open(directory_path, \"r\") as f:\n","    # 파일 내용을 읽습니다.\n","    data = f.read()\n","\n","# 파일 내용을 출력합니다.\n","print(data)\n","\n","'''\n","knife = 43 index 확인\n","'''\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":251},"id":"TUNUs1ZRC1K6","executionInfo":{"status":"error","timestamp":1700737301645,"user_tz":-540,"elapsed":24,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"54beeba2-8b11-407c-a4af-ab907eee0ff7"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-5f0d4c1c5da6>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 이미지를 읽습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 이미지를 표시합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"]}]},{"cell_type":"markdown","source":["### 기존 데이터셋 labels 객체 클래스 변경 (0->43)"],"metadata":{"id":"tnBpT7t_ECjn"}},{"cell_type":"code","source":["# 기존 dataset 의 라벨들 중 객체 클래스가 0인 것들을 43(knife)로 변경\n","\n","import os\n","\n","path_li = ['/content/dataset/train/labels', '/content/dataset/test/labels', '/content/dataset/valid/labels']\n","for path in path_li:\n","  class_to_replace = 0  # 변경하고자 하는 클래스 값\n","  replacement_class = 43  # 대체할 클래스 값\n","\n","  for filename in os.listdir(path):\n","      if filename.endswith('.txt'):\n","          filepath = os.path.join(path, filename)\n","          with open(filepath, 'r') as file:\n","              lines = file.readlines()\n","\n","          modified_lines = []\n","          for line in lines:\n","              line_split = line.strip().split()\n","              if line_split:  # 비어있는 줄은 건너뜁니다\n","                  current_class = int(line_split[0])  # 현재 클래스 값을 가져옵니다\n","                  if current_class == class_to_replace:\n","                      line_split[0] = str(replacement_class)  # 클래스를 변경합니다\n","                  modified_line = ' '.join(line_split) + '\\n'\n","                  modified_lines.append(modified_line)\n","\n","          # 변경된 내용을 파일에 다시 씁니다\n","          with open(filepath, 'w') as file:\n","              file.writelines(modified_lines)"],"metadata":{"id":"YRZViGNR8cH8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 이미지경로 -> **coco** txt 파일에 추가\n","    -기존 데이터셋 이미지를 coco 데이터셋 이미지 파일로 옮길것을 생각하고 경로를 지정함(상대경로)"],"metadata":{"id":"OHeFLvPRD9mb"}},{"cell_type":"code","source":["# 디렉토리 경로를 지정합니다.\n","directory_path = \"/content/dataset/train/images\"\n","\n","# 파일 경로를 지정합니다.\n","file_path = '/content/yolov7/coco/train2017.txt'\n","\n","# 파일을 엽니다.\n","with open(file_path, \"a\") as f:\n","    # 디렉토리 내부의 모든 파일을 반복합니다.\n","    for file in os.listdir(directory_path):\n","        # 파일 확장자가 jpg인지 확인합니다.\n","        if file.endswith(\".jpg\"):\n","            # 파일 이름을 붙여넣습니다.\n","            f.write(\"./images/train2017/{}\\n\".format(file))"],"metadata":{"id":"EUij9pVk9573"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 데이터셋의 test 디렉토리는 coco 데이터셋으로 옯겨서 사용하지 않음"],"metadata":{"id":"HIN18rDe_7UT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 디렉토리 경로를 지정합니다.\n","directory_path = \"/content/dataset/valid/images\"\n","\n","# 파일 이름을 지정합니다.\n","# file_name = \"my_file.txt\"\n","\n","# 파일 경로를 지정합니다.\n","file_path = '/content/yolov7/coco/val2017.txt'\n","\n","# 파일을 엽니다.\n","with open(file_path, \"a\") as f:\n","    # 디렉토리 내부의 모든 파일을 반복합니다.\n","    for file in os.listdir(directory_path):\n","        # 파일 확장자가 jpg인지 확인합니다.\n","        if file.endswith(\".jpg\"):\n","            # 파일 이름을 붙여넣습니다.\n","            f.write(\"./images/val2017/{}\\n\".format(file))"],"metadata":{"id":"UWPc5GzQ_0tn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 데이터 이동 (이미지 파일 >.jpg)"],"metadata":{"id":"cJ3kYnCpD6hz"}},{"cell_type":"code","source":["# 기존 데이터셋 train 안에 있는 이미지(jpg) -> coco 데이터셋 images train 파일로 이동\n","\n","import shutil\n","\n","# 원본 디렉토리 경로를 지정합니다.\n","source_directory_path = \"/content/dataset/train/images\"\n","\n","# 대상 디렉토리 경로를 지정합니다.\n","target_directory_path = \"/content/yolov7/coco/images/train2017\"\n","\n","# 원본 디렉토리 내부의 모든 파일을 대상으로 반복합니다.\n","for file in os.listdir(source_directory_path):\n","    # 파일 경로를 가져옵니다.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # 파일을 대상 디렉토리로 이동합니다.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"oTJzZZ1dAekC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 데이터셋 valid 안에 있는 이미지(jpg) -> coco 데이터셋 images val 파일로 이동\n","\n","import shutil\n","\n","# 원본 디렉토리 경로를 지정합니다.\n","source_directory_path = \"/content/dataset/valid/images\"\n","\n","# 대상 디렉토리 경로를 지정합니다.\n","target_directory_path = \"/content/yolov7/coco/images/val2017\"\n","\n","# 원본 디렉토리 내부의 모든 파일을 대상으로 반복합니다.\n","for file in os.listdir(source_directory_path):\n","    # 파일 경로를 가져옵니다.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # 파일을 대상 디렉토리로 이동합니다.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"8TBLruf5EKfl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 데이터 이동 (라벨파일 >.txt)"],"metadata":{"id":"wwA89787EnWk"}},{"cell_type":"code","source":["# 기존 데이터셋 train 안에 있는 이미지(jpg) -> coco 데이터셋 images train 파일로 이동\n","\n","import shutil\n","\n","# 원본 디렉토리 경로를 지정합니다.\n","source_directory_path = \"/content/dataset/train/labels\"\n","\n","# 대상 디렉토리 경로를 지정합니다.\n","target_directory_path = \"/content/yolov7/coco/labels/train2017\"\n","\n","# 원본 디렉토리 내부의 모든 파일을 대상으로 반복합니다.\n","for file in os.listdir(source_directory_path):\n","    # 파일 경로를 가져옵니다.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # 파일을 대상 디렉토리로 이동합니다.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"Ytp6aotgFAQC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 기존 데이터셋 valid 안에 있는 이미지(jpg) -> coco 데이터셋 images val 파일로 이동\n","\n","import shutil\n","\n","# 원본 디렉토리 경로를 지정합니다.\n","source_directory_path = \"/content/dataset/valid/labels\"\n","\n","# 대상 디렉토리 경로를 지정합니다.\n","target_directory_path = \"/content/yolov7/coco/labels/val2017\"\n","\n","# 원본 디렉토리 내부의 모든 파일을 대상으로 반복합니다.\n","for file in os.listdir(source_directory_path):\n","    # 파일 경로를 가져옵니다.\n","    file_path = os.path.join(source_directory_path, file)\n","\n","    # 파일을 대상 디렉토리로 이동합니다.\n","    shutil.copy(file_path, target_directory_path)\n"],"metadata":{"id":"wa2QvaE6EhQN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### coco.yaml 파일 변경\n","\n","\n","```\n","train: ./coco/train2017.txt  # 118287 images + 커스텀 데이터셋\n","val: ./coco/val2017.txt  # 5000 images + 커스텀 데이터셋\n","test: ./coco/test-dev2017.txt  # 20288 of 40670 images, submit to https://competitions.codalab.org/competitions/20794\n","\n","# number of classes\n","nc: 80\n","\n","# class names\n","names: [ 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n","         'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n","         'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n","         'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n","         'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n","         'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n","         'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n","         'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n","         'hair drier', 'toothbrush' ]\n","\n","```\n","\n"],"metadata":{"id":"zFUset5HF-5p"}},{"cell_type":"code","source":["# 기존 coco.yaml 파일 수정 불가로 인해 기존데이터셋 data.yaml 파일 yolov7/data 디렉에 복사해와서 수정필요\n","!cp /content/dataset/data.yaml /content/yolov7/data/data.yaml\n","\n","# 위 텍스트셸의 코드 덮어쓰기 및 저장 필요"],"metadata":{"id":"iONNXxuJHeZb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 학습"],"metadata":{"id":"2CpLJgPbIrfN"}},{"cell_type":"code","source":["%cd /content/yolov7\n","!python train.py --workers 1 --device 0 --batch-size 10 --epochs 8  --img 416 416 --data /content/yolov7/data/data.yaml --hyp data/hyp.scratch.custom.yaml --cfg cfg/training/yolov7.yaml --name yolov7-custom --weights yolov7.pt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j9NdbveNx3om","executionInfo":{"status":"ok","timestamp":1700785443749,"user_tz":-540,"elapsed":1340727,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"1f57b027-da50-4b2a-fce0-726b8e46182d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","2023-11-23 12:34:25.189238: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-11-23 12:34:25.238590: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-23 12:34:25.238654: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-23 12:34:25.238680: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-23 12:34:25.247594: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-11-23 12:34:26.270387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","YOLOR 🚀 v0.1-128-ga207844 torch 2.1.0+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40513.5625MB)\n","\n","Namespace(weights='yolov7.pt', cfg='cfg/training/yolov7.yaml', data='/content/yolov7/data/data.yaml', hyp='data/hyp.scratch.custom.yaml', epochs=8, batch_size=10, img_size=[416, 416], rect=False, resume=False, nosave=False, notest=False, noautoanchor=False, evolve=False, bucket='', cache_images=False, image_weights=False, device='0', multi_scale=False, single_cls=False, adam=False, sync_bn=False, local_rank=-1, workers=1, project='runs/train', entity=None, name='yolov7-custom', exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, upload_dataset=False, bbox_interval=-1, save_period=-1, artifact_alias='latest', freeze=[0], v5_metric=False, world_size=1, global_rank=-1, save_dir='runs/train/yolov7-custom2', total_batch_size=10)\n","\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.3, cls_pw=1.0, obj=0.7, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.2, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, paste_in=0.0, loss_ota=1\n","\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOR logging with 'pip install wandb' (recommended)\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1       928  models.common.Conv                      [3, 32, 3, 1]                 \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  5                -2  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n","  6                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  7                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  8                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n","  9                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 10  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 11                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 12                -1  1         0  models.common.MP                        []                            \n"," 13                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 14                -3  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 16          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 18                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 19                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 20                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 23  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 24                -1  1    263168  models.common.Conv                      [512, 512, 1, 1]              \n"," 25                -1  1         0  models.common.MP                        []                            \n"," 26                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 27                -3  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 28                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 29          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 30                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 31                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 32                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 33                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 34                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 35                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 36  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 37                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 38                -1  1         0  models.common.MP                        []                            \n"," 39                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 40                -3  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 41                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n"," 42          [-1, -3]  1         0  models.common.Concat                    [1]                           \n"," 43                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 44                -2  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 45                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 46                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 47                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 48                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 49  [-1, -3, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 50                -1  1   1050624  models.common.Conv                      [1024, 1024, 1, 1]            \n"," 51                -1  1   7609344  models.common.SPPCSPC                   [1024, 512, 1]                \n"," 52                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 53                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 54                37  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 55          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 56                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 57                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 58                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 59                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 60                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 61                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 62[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 63                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 64                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 65                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 66                24  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 67          [-1, -2]  1         0  models.common.Concat                    [1]                           \n"," 68                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 69                -2  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 70                -1  1     73856  models.common.Conv                      [128, 64, 3, 1]               \n"," 71                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 72                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 73                -1  1     36992  models.common.Conv                      [64, 64, 3, 1]                \n"," 74[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 75                -1  1     65792  models.common.Conv                      [512, 128, 1, 1]              \n"," 76                -1  1         0  models.common.MP                        []                            \n"," 77                -1  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 78                -3  1     16640  models.common.Conv                      [128, 128, 1, 1]              \n"," 79                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 80      [-1, -3, 63]  1         0  models.common.Concat                    [1]                           \n"," 81                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 82                -2  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 83                -1  1    295168  models.common.Conv                      [256, 128, 3, 1]              \n"," 84                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 85                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 86                -1  1    147712  models.common.Conv                      [128, 128, 3, 1]              \n"," 87[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n"," 88                -1  1    262656  models.common.Conv                      [1024, 256, 1, 1]             \n"," 89                -1  1         0  models.common.MP                        []                            \n"," 90                -1  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 91                -3  1     66048  models.common.Conv                      [256, 256, 1, 1]              \n"," 92                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 93      [-1, -3, 51]  1         0  models.common.Concat                    [1]                           \n"," 94                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 95                -2  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n"," 96                -1  1   1180160  models.common.Conv                      [512, 256, 3, 1]              \n"," 97                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 98                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n"," 99                -1  1    590336  models.common.Conv                      [256, 256, 3, 1]              \n","100[-1, -2, -3, -4, -5, -6]  1         0  models.common.Concat                    [1]                           \n","101                -1  1   1049600  models.common.Conv                      [2048, 512, 1, 1]             \n","102                75  1    328704  models.common.RepConv                   [128, 256, 3, 1]              \n","103                88  1   1312768  models.common.RepConv                   [256, 512, 3, 1]              \n","104               101  1   5246976  models.common.RepConv                   [512, 1024, 3, 1]             \n","105   [102, 103, 104]  1    460282  models.yolo.IDetect                     [80, [[12, 16, 19, 36, 40, 28], [36, 75, 76, 55, 72, 146], [142, 110, 192, 243, 459, 401]], [256, 512, 1024]]\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","Model Summary: 415 layers, 37622682 parameters, 37622682 gradients, 106.5 GFLOPS\n","\n","Transferred 558/566 items from yolov7.pt\n","Scaled weight_decay = 0.00046875\n","Optimizer groups: 95 .bias, 95 conv.weight, 98 other\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning 'coco/train2017' images and labels... 123152 found, 1021 missing, 0 empty, 0 corrupted: 100% 124173/124173 [01:43<00:00, 1204.85it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: coco/train2017.cache\n","\u001b[34m\u001b[1mval: \u001b[0mScanning 'coco/val2017' images and labels... 5670 found, 48 missing, 0 empty, 0 corrupted: 100% 5718/5718 [00:12<00:00, 463.63it/s] \n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: coco/val2017.cache\n","\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.21, Best Possible Recall (BPR) = 0.9730. Attempting to improve anchors, please wait...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 15342 of 856018 labels are < 3 pixels in size.\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 855585 points...\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9729 best possible recall, 4.00 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.272/0.653-mean/best, past_thr=0.468-mean: 14,14,  24,41,  62,36,  49,90,  126,78,  93,168,  246,134,  167,277,  356,262\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.6891: 100% 1000/1000 [01:24<00:00, 11.78it/s]\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9952 best possible recall, 4.30 anchors past thr\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.288/0.690-mean/best, past_thr=0.468-mean: 7,8,  9,21,  22,17,  22,42,  53,37,  46,89,  111,83,  105,184,  270,215\n","\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n","\n","Image sizes 416 train, 416 test\n","Using 1 dataloader workers\n","Logging results to runs/train/yolov7-custom2\n","Starting training for 8 epochs...\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       0/7     1.31G   0.02766   0.01852  0.009331   0.05551        52       416: 100% 12418/12418 [1:27:08<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [01:04<00:00,  4.44it/s]\n","                 all        5718       37083       0.428       0.496       0.417       0.259\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       1/7     3.96G   0.02925   0.02008   0.01139   0.06072        27       416: 100% 12418/12418 [1:26:44<00:00,  2.39it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.09it/s]\n","                 all        5718       37083        0.67       0.553       0.585       0.396\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       2/7     6.28G   0.03093   0.02151   0.01402   0.06647        46       416: 100% 12418/12418 [1:26:46<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.11it/s]\n","                 all        5718       37083       0.712       0.526       0.591       0.407\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       3/7     6.29G   0.03076   0.02165   0.01421   0.06662        21       416: 100% 12418/12418 [1:26:45<00:00,  2.39it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.11it/s]\n","                 all        5718       37083       0.666       0.552       0.591       0.407\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       4/7     6.29G   0.03007   0.02134   0.01347   0.06488        38       416: 100% 12418/12418 [1:26:50<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.12it/s]\n","                 all        5718       37083       0.671       0.556       0.596       0.411\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       5/7     6.29G   0.02905   0.02098   0.01241   0.06243        15       416: 100% 12418/12418 [1:27:02<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:55<00:00,  5.12it/s]\n","                 all        5718       37083       0.697       0.548       0.601       0.417\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       6/7     6.29G     0.028   0.02047   0.01138   0.05985        35       416: 100% 12418/12418 [1:27:10<00:00,  2.37it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.10it/s]\n","                 all        5718       37083       0.698       0.554       0.606       0.421\n","\n","     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n","       7/7     6.29G   0.02712   0.01984    0.0105   0.05745        41       416: 100% 12418/12418 [1:26:53<00:00,  2.38it/s]\n","               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 286/286 [00:56<00:00,  5.07it/s]\n","                 all        5718       37083       0.687       0.564       0.611       0.425\n","8 epochs completed in 11.725 hours.\n","\n","Optimizer stripped from runs/train/yolov7-custom2/weights/last.pt, 75.6MB\n","Optimizer stripped from runs/train/yolov7-custom2/weights/best.pt, 75.6MB\n"]}]},{"cell_type":"code","source":["!cp -a /content/yolov7/runs/train/yolov7-custom2/weights/best.pt /content/drive/MyDrive/Yolo_Project_v3/modle.pt"],"metadata":{"id":"7NEgQBFCNfST"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -a /content/yolov7/runs/train/yolov7-custom2/weights/best.pt /content/drive/MyDrive/Yolo_Project_v3/custom+coco.pt"],"metadata":{"id":"7kXl1SR9Pry2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 모델 Detect"],"metadata":{"id":"YbbEoEpWuE-9"}},{"cell_type":"code","source":["%cd /content/yolov7\n","!python /content/yolov7/detect.py --weights /content/yolov7/runs/train/yolov7-custom2/weights/best.pt --img 416 --conf 0.4 --source /content/detect_images/"],"metadata":{"id":"YJH5ZxMNuJcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import argparse\n","import time\n","from pathlib import Path\n","\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n","    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n","\n","\n","def detect(source, conf_thres, save_img=True):\n","    # weights = '/content/model.pt'\n","    # weights = '/content/yolov7x.pt'\n","\n","    weights = '/content/drive/MyDrive/Yolo_Project_v3/custom+coco.pt' # coco + 커스텀 데이터셋2개 병합\n","\n","    source.save('/content/input.png')\n","    source = '/content/input.png'\n","    img_size = 640\n","    conf_thres = conf_thres\n","    iou_thres = 0.45\n","    device = ''\n","    view_img = False\n","    save_txt = False\n","    save_conf = False\n","    nosave = False\n","    classes = None\n","    agnostic_nms = False\n","    augment=False\n","    update = False\n","    project = 'runs/detect'\n","    name='exp'\n","    exist_ok=False\n","    no_trace=False\n","\n","    imgsz = img_size\n","    trace = no_trace\n","    #source, weights, view_img, save_txt, imgsz, trace = source, weights, view_img, save_txt, img_size, not no_trace\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n","        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n","\n","    # Directories\n","    save_dir = Path(increment_path(Path(project) / name, exist_ok=exist_ok))  # increment run\n","    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Initialize\n","    set_logging()\n","    device = select_device(device)\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","    stride = int(model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","\n","    if trace:\n","        model = TracedModel(model, device, img_size)\n","\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Second-stage classifier\n","    classify = False\n","    if classify:\n","        modelc = load_classifier(name='resnet101', n=2)  # initialize\n","        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    if webcam:\n","        view_img = check_imshow()\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n","\n","    # Run inference\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    old_img_w = old_img_h = imgsz\n","    old_img_b = 1\n","\n","    t0 = time.time()\n","    for path, img, im0s, vid_cap in dataset:\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Warmup\n","        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n","            old_img_b = img.shape[0]\n","            old_img_h = img.shape[2]\n","            old_img_w = img.shape[3]\n","            for i in range(3):\n","                model(img, augment=augment)[0]\n","\n","        # Inference\n","        t1 = time_synchronized()\n","        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","            pred = model(img, augment=augment)[0]\n","        t2 = time_synchronized()\n","\n","        # Apply NMS\n","        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n","        t3 = time_synchronized()\n","\n","        # Apply Classifier\n","        if classify:\n","            pred = apply_classifier(pred, modelc, img, im0s)\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            if webcam:  # batch_size >= 1\n","                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n","            else:\n","                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","\n","            p = Path(p)  # to Path\n","            save_path = str(save_dir / p.name)  # img.jpg\n","            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n","            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","            if len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results\n","                for c in det[:, -1].unique():\n","                    n = (det[:, -1] == c).sum()  # detections per class\n","                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","\n","                # Write results\n","                for *xyxy, conf, cls in reversed(det):\n","                    if save_txt:  # Write to file\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n","                        with open(txt_path + '.txt', 'a') as f:\n","                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n","\n","                    if save_img or view_img:  # Add bbox to image\n","                        label = f'{names[int(cls)]} {conf:.2f}'\n","                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n","\n","            # Print time (inference + NMS)\n","            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","\n","            # Stream results\n","            if view_img:\n","                cv2.imshow(str(p), im0)\n","                cv2.waitKey(1)  # 1 millisecond\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'image':\n","                    cv2.imwrite(save_path, im0)\n","                    print(f\" The image with the result is saved in: {save_path}\")\n","                else:  # 'video' or 'stream'\n","                    if vid_path != save_path:  # new video\n","                        vid_path = save_path\n","                        if isinstance(vid_writer, cv2.VideoWriter):\n","                            vid_writer.release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                            save_path += '.mp4'\n","                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer.write(im0)\n","\n","    if save_txt or save_img:\n","        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n","        #print(f\"Results saved to {save_dir}{s}\")\n","\n","    print(f'Done. ({time.time() - t0:.3f}s)')\n","    return Path(save_path)\n","\n","\n","# detect('/content/input.mp4', 0.3) # gradio 사용없이 detect 함수실행"],"metadata":{"id":"_gpNCr1FvcBj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Gradio 인터페이스 연결"],"metadata":{"id":"Er_eZ3uquSeu"}},{"cell_type":"code","source":["import gradio as gr\n","import os\n","\n","\n","demo = gr.Interface(\n","    fn=detect,\n","    inputs=[gr.Image(type='pil'),\n","    gr.Slider(\n","        0.0,\n","        1,\n","        step=0.01,\n","        value=0.3,\n","        label='conf',\n","        info='conf'\n","    )],\n","    outputs='image',\n",")\n","demo.launch(debug=True)"],"metadata":{"id":"zpgy51ABvbWH"},"execution_count":null,"outputs":[]}]}