{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO6JKiREUyduP+NdhMO3EiA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F86t-ZyflUOS","executionInfo":{"status":"ok","timestamp":1700701497970,"user_tz":-540,"elapsed":17266,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"1e6cb21f-d6a9-4be0-8504-77bbe4dbfea9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/WongKinYiu/yolov7"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pOc8crH8l8Te","executionInfo":{"status":"ok","timestamp":1700701501577,"user_tz":-540,"elapsed":3612,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"1d0cac71-d80b-4118-d365-f23cbc1cfa2d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov7'...\n","remote: Enumerating objects: 1197, done.\u001b[K\n","remote: Counting objects: 100% (6/6), done.\u001b[K\n","remote: Compressing objects: 100% (5/5), done.\u001b[K\n","remote: Total 1197 (delta 2), reused 3 (delta 1), pack-reused 1191\u001b[K\n","Receiving objects: 100% (1197/1197), 74.23 MiB | 31.84 MiB/s, done.\n","Resolving deltas: 100% (517/517), done.\n"]}]},{"cell_type":"code","source":["!pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAGsPAiHmCg-","executionInfo":{"status":"ok","timestamp":1700701520820,"user_tz":-540,"elapsed":19245,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"28f81605-452f-46aa-cb64-b6bc0270cb45"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gradio\n","  Downloading gradio-4.5.0-py3-none-any.whl (16.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m74.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n","Collecting fastapi (from gradio)\n","  Downloading fastapi-0.104.1-py3-none-any.whl (92 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ffmpy (from gradio)\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gradio-client==0.7.0 (from gradio)\n","  Downloading gradio_client-0.7.0-py3-none-any.whl (302 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio)\n","  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.19.4)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n","Collecting orjson~=3.0 (from gradio)\n","  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n","Collecting pydantic>=2.0 (from gradio)\n","  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pydub (from gradio)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Collecting python-multipart (from gradio)\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.31.0)\n","Collecting semantic-version~=2.0 (from gradio)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Collecting tomlkit==0.12.0 (from gradio)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n","Collecting uvicorn>=0.14.0 (from gradio)\n","  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.0->gradio) (2023.6.0)\n","Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.0->gradio)\n","  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.13.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.66.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n","Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n","  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n","Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio)\n","  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m113.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typing-extensions~=4.0 (from gradio)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio) (2023.7.22)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n","Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n","  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n","Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n","Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (3.7.1)\n","Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n","  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore (from httpx->gradio)\n","  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio) (1.1.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.31.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.13.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n","Building wheels for collected packages: ffmpy\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=e460df145c8b1d6a5b82ceab607331e9eada619c05c578570631a7b80cdea7d2\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built ffmpy\n","Installing collected packages: pydub, ffmpy, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, pydantic-core, httpcore, pydantic, httpx, gradio-client, fastapi, gradio\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: pydantic\n","    Found existing installation: pydantic 1.10.13\n","    Uninstalling pydantic-1.10.13:\n","      Successfully uninstalled pydantic-1.10.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 colorama-0.4.6 fastapi-0.104.1 ffmpy-0.3.1 gradio-4.5.0 gradio-client-0.7.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 orjson-3.9.10 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.8.0 uvicorn-0.24.0.post1 websockets-11.0.3\n"]}]},{"cell_type":"code","source":["%cd yolov7\n","!pip install -r requirements.txt # YOLO 종속성 라이브러리 설치"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DIqOqRStmJSD","executionInfo":{"status":"ok","timestamp":1700701527763,"user_tz":-540,"elapsed":6946,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"cfc3e293-50e7-4180-8d94-0c9abc0e192b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/yolov7\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n","Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.8.0.76)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (9.4.0)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (1.11.3)\n","Requirement already satisfied: torch!=1.12.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.1.0+cu118)\n","Requirement already satisfied: torchvision!=0.13.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (0.16.0+cu118)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.66.1)\n","Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.20.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (2.14.1)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (0.12.2)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (7.34.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (5.9.5)\n","Collecting thop (from -r requirements.txt (line 36))\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2023.7.22)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (4.8.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (2.1.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.59.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.5.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (67.7.2)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.16.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.0.1)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 21)) (2023.3.post1)\n","Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 34))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (3.0.41)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 34)) (4.8.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 34)) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 34)) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 34)) (0.2.10)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 17)) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.7.0->-r requirements.txt (line 11)) (1.3.0)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 17)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 17)) (3.2.2)\n","Installing collected packages: jedi, thop\n","Successfully installed jedi-0.19.1 thop-0.1.1.post2209072238\n"]}]},{"cell_type":"code","source":["!cp /content/drive/MyDrive/Yolo_Project_v2/best.pt /content/model.pt"],"metadata":{"id":"MHH_vY0HmUtk","executionInfo":{"status":"ok","timestamp":1700701529366,"user_tz":-540,"elapsed":1605,"user":{"displayName":"문태서","userId":"03540612891035297255"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["#------"],"metadata":{"id":"WQdZlMOC0y-S"}},{"cell_type":"code","source":["import argparse\n","import time\n","from pathlib import Path\n","\n","import cv2\n","import torch\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n","    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel\n","\n","\n","def detect(source, conf_thres, save_img=True):\n","    # weights = '/content/model.pt'\n","    weights = '/content/yolov7x.pt'\n","\n","    # source.save('/content/input.mp4')\n","    # source = '/content/input.mp4'\n","    img_size = 640\n","    conf_thres = conf_thres\n","    iou_thres = 0.45\n","    device = ''\n","    view_img = False\n","    save_txt = False\n","    save_conf = False\n","    nosave = False\n","    classes = None\n","    agnostic_nms = False\n","    augment=False\n","    update = False\n","    project = 'runs/detect'\n","    name='exp'\n","    exist_ok=False\n","    no_trace=False\n","\n","    imgsz = img_size\n","    trace = no_trace\n","    #source, weights, view_img, save_txt, imgsz, trace = source, weights, view_img, save_txt, img_size, not no_trace\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","    webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(\n","        ('rtsp://', 'rtmp://', 'http://', 'https://'))\n","\n","    # Directories\n","    save_dir = Path(increment_path(Path(project) / name, exist_ok=exist_ok))  # increment run\n","    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n","\n","    # Initialize\n","    set_logging()\n","    device = select_device(device)\n","    half = device.type != 'cpu'  # half precision only supported on CUDA\n","\n","    # Load model\n","    model = attempt_load(weights, map_location=device)  # load FP32 model\n","    stride = int(model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride)  # check img_size\n","\n","    if trace:\n","        model = TracedModel(model, device, img_size)\n","\n","    if half:\n","        model.half()  # to FP16\n","\n","    # Second-stage classifier\n","    classify = False\n","    if classify:\n","        modelc = load_classifier(name='resnet101', n=2)  # initialize\n","        modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=device)['model']).to(device).eval()\n","\n","    # Set Dataloader\n","    vid_path, vid_writer = None, None\n","    if webcam:\n","        view_img = check_imshow()\n","        cudnn.benchmark = True  # set True to speed up constant image size inference\n","        dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","    else:\n","        dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","\n","    # Get names and colors\n","    names = model.module.names if hasattr(model, 'module') else model.names\n","    colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n","\n","    # Run inference\n","    if device.type != 'cpu':\n","        model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once\n","    old_img_w = old_img_h = imgsz\n","    old_img_b = 1\n","\n","    t0 = time.time()\n","    for path, img, im0s, vid_cap in dataset:\n","        img = torch.from_numpy(img).to(device)\n","        img = img.half() if half else img.float()  # uint8 to fp16/32\n","        img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","        if img.ndimension() == 3:\n","            img = img.unsqueeze(0)\n","\n","        # Warmup\n","        if device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n","            old_img_b = img.shape[0]\n","            old_img_h = img.shape[2]\n","            old_img_w = img.shape[3]\n","            for i in range(3):\n","                model(img, augment=augment)[0]\n","\n","        # Inference\n","        t1 = time_synchronized()\n","        with torch.no_grad():   # Calculating gradients would cause a GPU memory leak\n","            pred = model(img, augment=augment)[0]\n","        t2 = time_synchronized()\n","\n","        # Apply NMS\n","        pred = non_max_suppression(pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n","        t3 = time_synchronized()\n","\n","        # Apply Classifier\n","        if classify:\n","            pred = apply_classifier(pred, modelc, img, im0s)\n","\n","        # Process detections\n","        for i, det in enumerate(pred):  # detections per image\n","            if webcam:  # batch_size >= 1\n","                p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n","            else:\n","                p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","\n","            p = Path(p)  # to Path\n","            save_path = str(save_dir / p.name)  # img.jpg\n","            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # img.txt\n","            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","            if len(det):\n","                # Rescale boxes from img_size to im0 size\n","                det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","\n","                # Print results\n","                for c in det[:, -1].unique():\n","                    n = (det[:, -1] == c).sum()  # detections per class\n","                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n","\n","                # Write results\n","                for *xyxy, conf, cls in reversed(det):\n","                    if save_txt:  # Write to file\n","                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n","                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n","                        with open(txt_path + '.txt', 'a') as f:\n","                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n","\n","                    if save_img or view_img:  # Add bbox to image\n","                        label = f'{names[int(cls)]} {conf:.2f}'\n","                        plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n","\n","            # Print time (inference + NMS)\n","            print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","\n","            # Stream results\n","            if view_img:\n","                cv2.imshow(str(p), im0)\n","                cv2.waitKey(1)  # 1 millisecond\n","\n","            # Save results (image with detections)\n","            if save_img:\n","                if dataset.mode == 'image':\n","                    cv2.imwrite(save_path, im0)\n","                    print(f\" The image with the result is saved in: {save_path}\")\n","                else:  # 'video' or 'stream'\n","                    if vid_path != save_path:  # new video\n","                        vid_path = save_path\n","                        if isinstance(vid_writer, cv2.VideoWriter):\n","                            vid_writer.release()  # release previous video writer\n","                        if vid_cap:  # video\n","                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","                        else:  # stream\n","                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                            save_path += '.mp4'\n","                        vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","                    vid_writer.write(im0)\n","\n","    if save_txt or save_img:\n","        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n","        #print(f\"Results saved to {save_dir}{s}\")\n","\n","    print(f'Done. ({time.time() - t0:.3f}s)')\n","    return Path(save_path)\n","\n","\n","# detect('/content/input.mp4', 0.3) # gradio 사용없이 detect 함수실행"],"metadata":{"id":"12blOGAP1Pjv","executionInfo":{"status":"ok","timestamp":1700701693635,"user_tz":-540,"elapsed":415,"user":{"displayName":"문태서","userId":"03540612891035297255"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import gradio as gr\n","import os\n","\n","\n","demo = gr.Interface(\n","    fn=detect,\n","    inputs=[gr.Video(),\n","    gr.Slider(\n","        0.0,\n","        1,\n","        step=0.01,\n","        value=0.3,\n","        label='conf',\n","        info='conf'\n","    )],\n","    outputs='video',\n","\n","\n",")\n","demo.launch(debug=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"YPWCSpu7takr","executionInfo":{"status":"ok","timestamp":1700702143702,"user_tz":-540,"elapsed":441525,"user":{"displayName":"문태서","userId":"03540612891035297255"}},"outputId":"4e25aca9-ac41-495e-97d7-449dd870fec4"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","Running on public URL: https://6749030fddfa6edeee.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://6749030fddfa6edeee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Fusing layers... \n","video 1/1 (1/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 sports ball, Done. (1636.2ms) Inference, (24.7ms) NMS\n","video 1/1 (2/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 sports ball, Done. (1919.2ms) Inference, (1.1ms) NMS\n","video 1/1 (3/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (2036.1ms) Inference, (2.7ms) NMS\n","video 1/1 (4/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (1877.9ms) Inference, (0.6ms) NMS\n","video 1/1 (5/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 sports ball, 1 cup, Done. (1552.9ms) Inference, (0.6ms) NMS\n","video 1/1 (6/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1551.1ms) Inference, (0.6ms) NMS\n","video 1/1 (7/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1556.0ms) Inference, (0.7ms) NMS\n","video 1/1 (8/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1558.6ms) Inference, (0.6ms) NMS\n","video 1/1 (9/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1554.8ms) Inference, (0.6ms) NMS\n","video 1/1 (10/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (1574.2ms) Inference, (1.3ms) NMS\n","video 1/1 (11/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (1986.4ms) Inference, (0.7ms) NMS\n","video 1/1 (12/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (2020.9ms) Inference, (0.9ms) NMS\n","video 1/1 (13/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (1737.6ms) Inference, (0.6ms) NMS\n","video 1/1 (14/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 8 persons, 1 sports ball, Done. (1538.2ms) Inference, (0.6ms) NMS\n","video 1/1 (15/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 10 persons, 1 sports ball, Done. (1550.9ms) Inference, (0.8ms) NMS\n","video 1/1 (16/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 8 persons, 1 sports ball, Done. (1553.8ms) Inference, (0.6ms) NMS\n","video 1/1 (17/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (1553.2ms) Inference, (0.6ms) NMS\n","video 1/1 (18/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1552.2ms) Inference, (0.6ms) NMS\n","video 1/1 (19/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (2166.6ms) Inference, (1.9ms) NMS\n","video 1/1 (20/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, 1 skateboard, Done. (2269.5ms) Inference, (0.7ms) NMS\n","video 1/1 (21/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1933.9ms) Inference, (2.1ms) NMS\n","video 1/1 (22/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1547.2ms) Inference, (0.5ms) NMS\n","video 1/1 (23/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 2 sports balls, Done. (1563.1ms) Inference, (0.6ms) NMS\n","video 1/1 (24/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 2 sports balls, Done. (1552.9ms) Inference, (0.6ms) NMS\n","video 1/1 (25/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, 1 chair, Done. (1553.5ms) Inference, (0.6ms) NMS\n","video 1/1 (26/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 9 persons, 1 sports ball, Done. (1547.6ms) Inference, (0.6ms) NMS\n","video 1/1 (27/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 8 persons, 1 sports ball, Done. (1548.5ms) Inference, (0.6ms) NMS\n","video 1/1 (28/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, 1 chair, Done. (1979.3ms) Inference, (0.7ms) NMS\n","video 1/1 (29/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, Done. (2089.1ms) Inference, (0.7ms) NMS\n","video 1/1 (30/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, 1 baseball bat, 1 skateboard, Done. (1802.4ms) Inference, (0.6ms) NMS\n","video 1/1 (31/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1551.5ms) Inference, (0.6ms) NMS\n","video 1/1 (32/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, Done. (1578.1ms) Inference, (0.6ms) NMS\n","video 1/1 (33/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 sports ball, 1 chair, Done. (1563.0ms) Inference, (0.6ms) NMS\n","video 1/1 (34/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 sports ball, 1 baseball glove, 1 chair, Done. (1546.8ms) Inference, (1.1ms) NMS\n","video 1/1 (35/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 sports ball, 1 chair, Done. (1546.6ms) Inference, (0.6ms) NMS\n","video 1/1 (36/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 chair, Done. (1648.9ms) Inference, (0.9ms) NMS\n","video 1/1 (37/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 sports ball, 1 chair, Done. (1997.5ms) Inference, (0.7ms) NMS\n","video 1/1 (38/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 sports ball, Done. (2010.2ms) Inference, (1.0ms) NMS\n","video 1/1 (39/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 sports ball, Done. (1669.5ms) Inference, (0.6ms) NMS\n","video 1/1 (40/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1543.3ms) Inference, (0.6ms) NMS\n","video 1/1 (41/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1555.7ms) Inference, (0.6ms) NMS\n","video 1/1 (42/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1562.3ms) Inference, (0.6ms) NMS\n","video 1/1 (43/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1559.0ms) Inference, (0.8ms) NMS\n","video 1/1 (44/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1572.8ms) Inference, (0.6ms) NMS\n","video 1/1 (45/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (1781.2ms) Inference, (0.7ms) NMS\n","video 1/1 (46/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (2046.7ms) Inference, (3.6ms) NMS\n","video 1/1 (47/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (1996.9ms) Inference, (0.6ms) NMS\n","video 1/1 (48/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1565.0ms) Inference, (0.6ms) NMS\n","video 1/1 (49/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1568.9ms) Inference, (3.1ms) NMS\n","video 1/1 (50/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1557.2ms) Inference, (0.6ms) NMS\n","video 1/1 (51/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1551.2ms) Inference, (0.6ms) NMS\n","video 1/1 (52/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, 1 sports ball, Done. (1548.2ms) Inference, (0.6ms) NMS\n","video 1/1 (53/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1549.9ms) Inference, (2.1ms) NMS\n","video 1/1 (54/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1940.6ms) Inference, (0.8ms) NMS\n","video 1/1 (55/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (2016.2ms) Inference, (0.7ms) NMS\n","video 1/1 (56/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1831.5ms) Inference, (0.6ms) NMS\n","video 1/1 (57/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1569.5ms) Inference, (2.0ms) NMS\n","video 1/1 (58/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1545.6ms) Inference, (0.6ms) NMS\n","video 1/1 (59/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1553.6ms) Inference, (1.9ms) NMS\n","video 1/1 (60/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1554.6ms) Inference, (0.6ms) NMS\n","video 1/1 (61/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1552.5ms) Inference, (0.6ms) NMS\n","video 1/1 (62/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1552.7ms) Inference, (2.0ms) NMS\n","video 1/1 (63/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1985.7ms) Inference, (0.7ms) NMS\n","video 1/1 (64/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (2000.3ms) Inference, (0.7ms) NMS\n","video 1/1 (65/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1735.1ms) Inference, (0.6ms) NMS\n","video 1/1 (66/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1559.9ms) Inference, (0.6ms) NMS\n","video 1/1 (67/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1550.4ms) Inference, (0.5ms) NMS\n","video 1/1 (68/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1560.7ms) Inference, (0.6ms) NMS\n","video 1/1 (69/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 3 persons, Done. (1550.3ms) Inference, (0.6ms) NMS\n","video 1/1 (70/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 3 persons, Done. (1943.1ms) Inference, (0.7ms) NMS\n","video 1/1 (71/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (2163.6ms) Inference, (3.4ms) NMS\n","video 1/1 (72/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 3 persons, Done. (2148.1ms) Inference, (0.7ms) NMS\n","video 1/1 (73/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, 1 skateboard, Done. (2206.5ms) Inference, (1.0ms) NMS\n","video 1/1 (74/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1896.1ms) Inference, (0.6ms) NMS\n","video 1/1 (75/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1577.9ms) Inference, (0.6ms) NMS\n","video 1/1 (76/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1567.4ms) Inference, (0.6ms) NMS\n","video 1/1 (77/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, 1 chair, Done. (1555.2ms) Inference, (0.6ms) NMS\n","video 1/1 (78/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, 1 chair, Done. (1540.9ms) Inference, (0.7ms) NMS\n","video 1/1 (79/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1556.5ms) Inference, (0.6ms) NMS\n","video 1/1 (80/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 4 persons, Done. (1574.1ms) Inference, (1.3ms) NMS\n","video 1/1 (81/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1984.6ms) Inference, (0.8ms) NMS\n","video 1/1 (82/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 chair, Done. (2006.7ms) Inference, (0.8ms) NMS\n","video 1/1 (83/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 chair, Done. (1737.2ms) Inference, (0.6ms) NMS\n","video 1/1 (84/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 chair, Done. (1552.9ms) Inference, (0.6ms) NMS\n","video 1/1 (85/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1550.2ms) Inference, (0.5ms) NMS\n","video 1/1 (86/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1575.7ms) Inference, (0.6ms) NMS\n","video 1/1 (87/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1573.6ms) Inference, (0.6ms) NMS\n","video 1/1 (88/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1599.2ms) Inference, (0.6ms) NMS\n","video 1/1 (89/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1684.3ms) Inference, (0.8ms) NMS\n","video 1/1 (90/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (2017.4ms) Inference, (2.9ms) NMS\n","video 1/1 (91/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (2015.0ms) Inference, (3.0ms) NMS\n","video 1/1 (92/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1605.9ms) Inference, (0.6ms) NMS\n","video 1/1 (93/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1555.6ms) Inference, (0.6ms) NMS\n","video 1/1 (94/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1571.2ms) Inference, (0.7ms) NMS\n","video 1/1 (95/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1547.5ms) Inference, (0.6ms) NMS\n","video 1/1 (96/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1577.0ms) Inference, (0.5ms) NMS\n","video 1/1 (97/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1556.4ms) Inference, (0.6ms) NMS\n","video 1/1 (98/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (1829.1ms) Inference, (0.7ms) NMS\n","video 1/1 (99/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 skateboard, Done. (2003.0ms) Inference, (0.8ms) NMS\n","video 1/1 (100/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, Done. (1983.5ms) Inference, (0.5ms) NMS\n","video 1/1 (101/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 5 persons, 1 chair, Done. (1552.9ms) Inference, (0.6ms) NMS\n","video 1/1 (102/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (1560.3ms) Inference, (0.6ms) NMS\n","video 1/1 (103/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1561.5ms) Inference, (0.6ms) NMS\n","video 1/1 (104/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 7 persons, 1 skateboard, Done. (1562.6ms) Inference, (0.6ms) NMS\n","video 1/1 (105/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1544.3ms) Inference, (0.6ms) NMS\n","video 1/1 (106/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 8 persons, 1 skateboard, 1 chair, Done. (1559.7ms) Inference, (0.6ms) NMS\n","video 1/1 (107/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1955.5ms) Inference, (0.7ms) NMS\n","video 1/1 (108/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (2033.7ms) Inference, (0.7ms) NMS\n","video 1/1 (109/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1790.0ms) Inference, (0.6ms) NMS\n","video 1/1 (110/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (1555.3ms) Inference, (0.6ms) NMS\n","video 1/1 (111/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1548.4ms) Inference, (0.6ms) NMS\n","video 1/1 (112/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1555.4ms) Inference, (0.6ms) NMS\n","video 1/1 (113/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1559.0ms) Inference, (2.0ms) NMS\n","video 1/1 (114/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, 1 skateboard, Done. (1553.2ms) Inference, (0.6ms) NMS\n","video 1/1 (115/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (1583.9ms) Inference, (0.6ms) NMS\n","video 1/1 (116/116) /tmp/gradio/d8fc1847040207b5672eedcbb05f80b144dcc3b9/input_3s.mp4: 6 persons, Done. (2018.4ms) Inference, (0.7ms) NMS\n","Done. (200.918s)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/gradio/components/video.py:274: UserWarning: Video does not have browser-compatible container or codec. Converting to mp4\n","  warnings.warn(\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n","    output = await route_utils.call_process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n","    prediction = await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n","    response = f(*args, **kwargs)\n","  File \"<ipython-input-7-e1c4c270a7b4>\", line 44, in detect\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","AttributeError: 'NoneType' object has no attribute 'endswith'\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 456, in call_prediction\n","    output = await route_utils.call_process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n","    output = await app.get_blocks().process_api(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1522, in process_api\n","    result = await self.call_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1144, in call_function\n","    prediction = await anyio.to_thread.run_sync(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n","    return await get_asynclib().run_sync_in_worker_thread(\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n","    return await future\n","  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n","    result = context.run(func, *args)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 674, in wrapper\n","    response = f(*args, **kwargs)\n","  File \"<ipython-input-7-e1c4c270a7b4>\", line 44, in detect\n","    save_img = not nosave and not source.endswith('.txt')  # save inference images\n","AttributeError: 'NoneType' object has no attribute 'endswith'\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 501, in process_events\n","    response = await self.call_prediction(awake_events, batch)\n","  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 465, in call_prediction\n","    raise Exception(str(error) if show_error else None) from error\n","Exception: None\n"]},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://6749030fddfa6edeee.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":8}]}]}